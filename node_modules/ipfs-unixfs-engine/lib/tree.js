'use strict';

var _typeof = typeof Symbol === "function" && typeof Symbol.iterator === "symbol" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === "function" && obj.constructor === Symbol ? "symbol" : typeof obj; };

var mh = require('multihashes');
var UnixFS = require('ipfs-unixfs');
var merkleDAG = require('ipfs-merkle-dag');

var DAGLink = merkleDAG.DAGLink;
var DAGNode = merkleDAG.DAGNode;

module.exports = function (files, dagService, source, cb) {
  // file struct
  // {
  //   path: // full path
  //   multihash: // multihash of the dagNode
  //   size: // cumulative size
  //   dataSize: // dagNode size
  // }

  // 1) convert files to a tree
  // for each path, split, add to a json tree and in the end the name of the
  // file points to an object that is has a key multihash and respective value
  // { foo: { bar: { baz.txt: <multihash> }}}
  // the stop condition is if the value is not an object
  var fileTree = {};
  files.forEach(function (file) {
    var splitted = file.path.split('/');
    if (splitted.length === 1) {
      return; // adding just one file
      // fileTree[file.path] = bs58.encode(file.multihash).toString()
    }
    if (splitted[0] === '') {
      splitted = splitted.slice(1);
    }
    var tmpTree = fileTree;

    for (var i = 0; i < splitted.length; i++) {
      if (!tmpTree[splitted[i]]) {
        tmpTree[splitted[i]] = {};
      }
      if (i === splitted.length - 1) {
        tmpTree[splitted[i]] = file.multihash;
      } else {
        tmpTree = tmpTree[splitted[i]];
      }
    }
  });

  if (Object.keys(fileTree).length === 0) {
    return cb(); // no dirs to be created
  }

  // 2) create a index for multihash: { size, dataSize } so
  // that we can fetch these when creating the merkle dag nodes

  var mhIndex = {};

  files.forEach(function (file) {
    mhIndex[mh.toB58String(file.multihash)] = {
      size: file.size,
      dataSize: file.dataSize
    };
  });

  // 3) expand leaves recursively
  // create a dirNode
  // Object.keys
  // If the value is an Object
  //   create a dir Node
  //   Object.keys
  //   Once finished, add the result as a link to the dir node
  // If the value is not an object
  //   add as a link to the dirNode

  var pendingWrites = 0;

  function traverse(tree, path, done) {
    var _this = this;

    var keys = Object.keys(tree);
    var tmpTree = tree;
    keys.map(function (key) {
      if (_typeof(tmpTree[key]) === 'object' && !Buffer.isBuffer(tmpTree[key])) {
        tmpTree[key] = traverse.call(_this, tmpTree[key], path ? path + '/' + key : key, done);
      }
    });

    // at this stage, all keys are multihashes
    // create a dir node
    // add all the multihashes as links
    // return this new node multihash

    var d = new UnixFS('directory');
    var n = new DAGNode();

    keys.forEach(function (key) {
      var b58mh = mh.toB58String(tmpTree[key]);
      var l = new DAGLink(key, mhIndex[b58mh].size, tmpTree[key]);
      n.addRawLink(l);
    });

    n.data = d.marshal();

    pendingWrites++;
    dagService.put(n, function (err) {
      pendingWrites--;
      if (err) {
        source.push(new Error('failed to store dirNode'));
      } else if (path) {
        source.push({
          path: path,
          multihash: n.multihash(),
          size: n.size()
        });
      }

      if (pendingWrites <= 0) {
        done();
      }
    });

    if (!path) {
      return;
    }

    mhIndex[mh.toB58String(n.multihash())] = { size: n.size() };
    return n.multihash();
  }

  traverse(fileTree, null, cb);
};